# -*- coding: utf-8 -*-
"""Analisis XGBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dRg4szFEqm5bvGZ-JENTKmBXR4a92RI_

## **Analisis XGBoost: Memprediksi Jumlah Pembelian (Purchase Amount)**

# **Library Yang Dibutuhkan**
"""

#Import Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""## **MEMANGGIL DATA**"""

#Load Data
df = pd.read_csv('/content/shopping_behavior_updated.csv')
print(df)

"""# **Analisis Data Eksplorasi (EDA)**"""

# Menampilkan 5 baris pertama data
print("\n--- 5 Baris Pertama Data ---")
print(df.head())

# Menampilkan informasi umum tentang data (tipe data, non-null counts)
print("\n--- Informasi Dataset ---")
df.info()

# Menampilkan statistik deskriptif untuk kolom numerik
print("\n--- Statistik Deskriptif ---")
print(df.describe())

# Memeriksa nilai yang hilang
print("\n--- Jumlah Nilai Hilang per Kolom ---")
print(df.isnull().sum())

# Memeriksa nilai unik untuk kolom kategorikal
print("\n--- Nilai Unik Kolom Kategorikal ---")
for column in df.select_dtypes(include='object').columns:
    print(f"{column}: {df[column].nunique()} unique values")
    if df[column].nunique() < 20: # Tampilkan nilai unik jika tidak terlalu banyak
        print(df[column].unique())

# Visualisasi distribusi variabel target 'Purchase Amount (USD)'
plt.figure(figsize=(10, 6))
sns.histplot(df['Purchase Amount (USD)'], kde=True, bins=30)
plt.title('Distribusi Jumlah Pembelian (Purchase Amount)')
plt.xlabel('Jumlah Pembelian (USD)')
plt.ylabel('Frekuensi')
plt.show()

# Visualisasi hubungan antara variabel kategorikal dan 'Purchase Amount (USD)'
categorical_cols = df.select_dtypes(include='object').columns.tolist()
if 'Customer ID' in categorical_cols:
    categorical_cols.remove('Customer ID') # Hapus Customer ID jika ada

n_cols = len(categorical_cols)
n_rows = (n_cols + 2) // 3 # Calculate the number of rows needed

plt.figure(figsize=(18, n_rows * 6)) # Adjust figure size based on number of rows
for i, col in enumerate(categorical_cols):
    plt.subplot(n_rows, 3, i + 1)
    sns.boxplot(x=col, y='Purchase Amount (USD)', data=df)
    plt.title(f'Purchase Amount by {col}')
    plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Visualisasi korelasi antar variabel numerik (jika ada lebih dari satu)
numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
if len(numeric_cols) > 1:
    plt.figure(figsize=(10, 8))
    sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', fmt=".2f")
    plt.title('Matriks Korelasi Variabel Numerik')
    plt.show()

"""## **Pembersihan Data (Data Cleaning)**"""

# Menghapus kolom 'Customer ID' karena tidak relevan untuk pemodelan
if 'Customer ID' in df.columns:
    df = df.drop('Customer ID', axis=1)
    print("\nKolom 'Customer ID' telah dihapus.")

# Memeriksa dan menangani duplikat
print(f"\nJumlah baris duplikat sebelum dihapus: {df.duplicated().sum()}")
df.drop_duplicates(inplace=True)
print(f"Jumlah baris duplikat setelah dihapus: {df.duplicated().sum()}")

# Mengganti nama kolom untuk kemudahan akses (opsional, tapi direkomendasikan)
df.columns = df.columns.str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('__', '_').str.lower()
print("\nNama kolom telah diseragamkan:")
print(df.columns)

# Memeriksa kembali nilai hilang setelah pembersihan awal
print("\nJumlah Nilai Hilang per Kolom setelah pembersihan awal:")
print(df.isnull().sum())

"""## **Rekayasa Fitur (Feature Engineering)**"""

# Mengubah kolom 'Subscription Status' menjadi numerik (0/1)
df['subscription_status'] = df['subscription_status'].map({'Yes': 1, 'No': 0})
print("\nKolom 'subscription_status' telah diubah menjadi numerik.")

# Mengubah kolom 'Discount Applied' menjadi numerik (0/1)
df['discount_applied'] = df['discount_applied'].map({'Yes': 1, 'No': 0})
print("Kolom 'discount_applied' telah diubah menjadi numerik.")

# Mengubah kolom 'Promo Code Used' menjadi numerik (0/1)
df['promo_code_used'] = df['promo_code_used'].map({'Yes': 1, 'No': 0})
print("Kolom 'promo_code_used' telah diubah menjadi numerik.")

"""### **NOTED**
1. Encoding variabel kategorikal lainnya menggunakan Label Encoding atau One-Hot Encoding
2. Untuk XGBoost, Label Encoding seringkali cukup baik untuk fitur dengan banyak kategori,
tetapi One-Hot Encoding lebih aman untuk menghindari asumsi ordinalitas.
3. Kita akan menggunakan One-Hot Encoding untuk sebagian besar, dan Label Encoding untuk yang spesifik jika diperlukan.
"""

# Kolom yang akan di-One-Hot Encode
cols_to_onehot = ['gender', 'item_purchased', 'category', 'location', 'size', 'color', 'season', 'payment_method', 'frequency_of_purchases']

# Terapkan One-Hot Encoding
df = pd.get_dummies(df, columns=cols_to_onehot, drop_first=True) # drop_first=True untuk menghindari multicollinearity
print("\nVariabel kategorikal telah di-One-Hot Encode.")
print(f"Jumlah kolom setelah One-Hot Encoding: {df.shape[1]}")

# Menampilkan 5 baris pertama data setelah feature engineering
print("\n--- 5 Baris Pertama Data Setelah Feature Engineering ---")
print(df.head())

"""## **Membagi Data menjadi set pelatihan (training set) dan set pengujian (testing set)**"""

# Mendefinisikan fitur (X) dan target (y)
X = df.drop('purchase_amount_usd', axis=1)
y = df['purchase_amount_usd']

# Membagi data menjadi training dan testing set
# random_state digunakan agar hasil pembagian konsisten setiap kali dijalankan
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\nUkuran X_train: {X_train.shape}")
print(f"Ukuran X_test: {X_test.shape}")
print(f"Ukuran y_train: {y_train.shape}")
print(f"Ukuran y_test: {y_test.shape}")

"""## **Pembangunan Model XGBoost**"""

# Inisialisasi model XGBoost Regressor
# Anda bisa menyesuaikan hyperparameter di sini
# Contoh hyperparameter umum: n_estimators, learning_rate, max_depth, subsample, colsample_bytree
xgb_model = XGBRegressor(objective='reg:squarederror', # Objective untuk regresi
                         n_estimators=100,             # Jumlah pohon
                         learning_rate=0.1,            # Tingkat pembelajaran
                         max_depth=5,                  # Kedalaman maksimum pohon
                         subsample=0.8,                # Proporsi sampel yang digunakan untuk melatih setiap pohon
                         colsample_bytree=0.8,         # Proporsi fitur yang digunakan untuk melatih setiap pohon
                         random_state=42,
                         n_jobs=-1)                    # Menggunakan semua core CPU yang tersedia
print("\nModel XGBoost diinisialisasi.")

# Melatih model
print("Melatih model XGBoost...")

# Apply Label Encoding to the 'shipping_type' column
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
X_train['shipping_type'] = le.fit_transform(X_train['shipping_type'])
X_test['shipping_type'] = le.transform(X_test['shipping_type'])

xgb_model.fit(X_train, y_train)
print("Model XGBoost selesai dilatih.")

"""## **Evaluasi Model**"""

# Membuat prediksi pada set pengujian
y_pred = xgb_model.predict(X_test)

# Menghitung metrik evaluasi
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\n--- Metrik Evaluasi Model XGBoost ---")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R2): {r2:.2f}")

# Visualisasi hasil prediksi vs. nilai aktual
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Garis y=x
plt.title('Prediksi vs. Nilai Aktual (XGBoost)')
plt.xlabel('Jumlah Pembelian Aktual (USD)')
plt.ylabel('Jumlah Pembelian Prediksi (USD)')
plt.grid(True)
plt.show()

# Visualisasi residual
residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
sns.histplot(residuals, kde=True, bins=30)
plt.title('Distribusi Residuals')
plt.xlabel('Residuals (Aktual - Prediksi)')
plt.ylabel('Frekuensi')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--', lw=2)
plt.title('Residuals vs. Prediksi')
plt.xlabel('Jumlah Pembelian Prediksi (USD)')
plt.ylabel('Residuals')
plt.grid(True)
plt.show()

"""## **Analisis Pentingnya Fitur (Feature Importance)**"""

# Mendapatkan pentingnya fitur dari model XGBoost
feature_importances = xgb_model.feature_importances_

# Membuat DataFrame untuk visualisasi
features_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})
features_df = features_df.sort_values(by='Importance', ascending=False)
print("\n--- Pentingnya Fitur (Top 10) ---")
print(features_df.head(10))

# Visualisasi pentingnya fitur
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=features_df.head(15), palette='viridis')
plt.title('Pentingnya Fitur dalam Model XGBoost')
plt.xlabel('Pentingnya')
plt.ylabel('Fitur')
plt.show()

"""## **Kesimpulan dan Langkah Selanjutnya**"""

print("\n--- Kesimpulan ---")
print("Model XGBoost telah dilatih untuk memprediksi 'Purchase Amount (USD)'.")
print(f"Kinerja model (R-squared) adalah {r2:.2f}, yang menunjukkan bahwa {r2*100:.2f}% variabilitas dalam jumlah pembelian dapat dijelaskan oleh fitur-fitur dalam model.")
print("Fitur-fitur penting telah diidentifikasi, memberikan wawasan tentang faktor-faktor yang paling memengaruhi jumlah pembelian.")

print("\n--- Langkah Selanjutnya yang Disarankan ---")
print("1. **Tuning Hyperparameter:** Gunakan teknik seperti GridSearchCV atau RandomizedSearchCV untuk menemukan kombinasi hyperparameter terbaik yang dapat meningkatkan kinerja model lebih lanjut.")
print("2. **Validasi Silang:** Terapkan validasi silang (Cross-Validation) untuk mendapatkan estimasi kinerja model yang lebih robust dan mengurangi risiko overfitting.")
print("3. **Analisis Residual Lebih Lanjut:** Jika distribusi residual tidak normal atau menunjukkan pola, mungkin ada informasi yang belum ditangkap oleh model.")
print("4. **Eksplorasi Fitur Tambahan:** Pertimbangkan untuk membuat fitur rekayasa yang lebih kompleks atau mengintegrasikan sumber data eksternal jika tersedia.")
print("5. **Interpretasi Model:** Gunakan alat seperti SHAP (SHapley Additive exPlanations) untuk interpretasi model yang lebih mendalam, terutama untuk memahami bagaimana setiap fitur memengaruhi prediksi individu.")
print("6. **Deployment:** Jika kinerja sudah memuaskan, model dapat dipertimbangkan untuk deployment.")